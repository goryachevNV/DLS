# Deep Learning (семестр 2, осень 2025)

## https://stepik.org/course/251729/syllabus
Данный курс на Stepik соответствует второму семестру Deep Learning School.

## Материалы первого курса Deep Learning School (DLS) (ML + CV)
https://github.com/DeepLearningSchool/part_2_nlp

### [l_01] Организационная информация
Здесь вы найдёте всю необходимую информацию о курсе.
> 1.1 О курсе.

### [l_02] Введение в NLP. Эмбеддинги слов.
В этом модуле мы поговорим об основах Natural Language Processing и эмбеддингах слов.
> 2.1 Лекция. Эмбеддинги слов. Татьяна Гайнцева.
> 2.2 Семинар. Обработка и классификация текстов. Антон Астахов.

### [l_03] Домашнее задание. Ранжирование текстов на основе эмбеддингов
> 3.1 Ранжирование текстов на основе эмбеддингов.

### [l_04] Рекуррентные нейронные сети (RNN)
В этом модуле вы узнаете, что такое рекуррентные нейронные сети, а также научитесь применять их для решения задачи классификации текстов.
> 4.1 Лекция. Рекуррентные нейронные сети. Татьяна Гайнцева.
> 4.2 Семинар. Классификация текста с помощью RNN. Антон Земеров.

### [l_05] Домашнее задание. Классификация текста с помощью RNN
В этом домашнем задании вы обучите модель классификации текста на основе RNN.
> 5.1 Домашнее задание. Классификация текста с помощью RNN

### [l_06] Языковое моделирование
В этом модуле вы изучите задачу языкового моделирования, классические и нейросетевые методы её решения, Вы познакомитесь с метриками языкового моделирования и методами генерации, а также обучите свою языковую модель.
> 6.1 Лекция. Языковое моделирование. Антон Земеров.
> 6.2 Семинар. Языковое моделирование. Антон Земеров.

### [l_07] Домашнее задание. Языковое моделирование
В этом задании вам предстоит обучить языковую модель с помощью рекуррентной нейронной сети. В отличие от семинарского занятия, вам необходимо будет работать с отдельными словами, а не буквами.
> 7.1 Домашнее задание. Языковое моделирование

### [l_08] Машинный перевод и механизм Attention
В этом модуле мы обсудим задачу машинного перевода и архитектурой для ее решения. Недостатки полученной модели приведут нас к идее механизма Attention.
> 8.1 Лекция. Машинный перевод и механизм Attention
> 8.2 Семинар. Машинный перевод
> 8.3 Дополнительные материалы

### [l_09] Архитектура Transformer
В этом модуле мы изучим устройство модели Transformer — архитектуре, полностью основанной на attention, которая совершила революцию в области NLP и стала классической.
> 9.1 Лекция. Attention и трансформер. Татьяна Гайнцева.
> 9.2 Семинар. Attention и трансформеры. Игорь Щукин.
> 9.3 Дополнительные материалы.

### [l_10] Предобучение и дообучение языковых моделей
В этом модуле мы подробнее поговорим о современных методах предобучения языковых моделей, а также научимся файнтьюнить языковые модели для решения прикладных задач NLP
> 10.1 Лекция. Предобучение и файнтьюнинг LM. Антон Земеров.
> 10.2 Семинар. Файнтьюнинг BART для суммаризации. Антон Земеров.

### [l_11] Домашнее задание. Предобучение и дообучение языковых моделей
В этом домашнем задании вы научитесь файнтюнить современные языковые модели для задачи классификации
> 11.1 Домашнее задание. Трансформеры

### [l_12] От GPT до GPT-3. Zero-shot Learning.
В этом модуле вы познакомитесь с устройством GPT-подобных моделей и проследите эволюцию от первых версий GPT до GPT-3. Также мы поговорим о такой вещи как Zero-shot Learning
> 12.1 Лекция. GPT-модели

### [l_13] GPT-2, GPT-3, RAG
В этом модуле вы познакомитесь с развитием GPT-based моделями, а также узнаете, что такое RAG.
> 13.1 Лекция. GPT2 и далее
> 13.2 Семинар. RAG

### [l_14]  Домашнее задание. RAG
> 14.1 Домашнее задание. RAG

### [l_15] Интерпретируемость трансформеров
В этом модуле вы познакомитесь с интерпретацией трансформеров: узнаете, что такое SAE, поймете интуицию, стоящую за attention и что же такое circuit.
> 15.1 Лекция. Интерпретируемость трансформеров.

### [l_16] Детекция сгенерированных текстов
> 16.1 Лекция. Детекция сгенерированных текстов.
> 16.2 Семинар. Детекция сгенерированных текстов.

### [l_17] Домашнее задание. Детекция сгенерированных текстов.
> 17.1 Домашнее задание. Детекция сгенерированных текстов.